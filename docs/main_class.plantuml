@startuml

class SquashedGaussianMLPActor {
    - __init__(self, obs_dim, act_dim, hidden_sizes, activation, act_limit) : void
    + forward(self, obs, deterministic=False, with_logprob=True) : pi_action, logp_pi
}

class MLPQFunction{
    - __init__(self, obs_dim, act_dim, hidden_sizes, activation) : void
    + forward(self, obs, act) : torch.squeeze(q, -1)
}

class MLPActorCritic{
    - __init__(self, observation_space, action_space, hidden_sizes=(256,256), activation=nn.ReLU): void
    + act(self, obs, deterministic=False): a.numpy
}

class core{
    + combined_shape(length, shape=None):(length, shape) if np.isscalar(shape) else (length, *shape)
    + mlp(sizes, activation, output_activation=nn.Identity) : nn.Sequential(*layers)
    + count_vars(module) : sum([np.prod(p.shape) for p in module.parameters()])
}

SquashedGaussianMLPActor <|-- torch.nn.Module
MLPQFunction <|-- torch.nn.Module
torch.nn.Module --|> MLPActorCritic

SquashedGaussianMLPActor <|-- core
MLPQFunction <|-- core
MLPActorCritic *-- SquashedGaussianMLPActor
MLPActorCritic *-- MLPQFunction

class ReplayBuffer {
    - __init__(self, obs_dim, act_dim, size): void
    + store(self, obs, act, rew, next_obs, done): void
    + sample_batch(self, batch_size=32): {k: torch.as_tensor(v, dtype=torch.float32) for k,v in batch.items()}
}

@enduml


